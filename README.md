# ğŸ¥ Medical Chatbot - NexgAI AI Engineering Challenge

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![LangGraph](https://img.shields.io/badge/LangGraph-Latest-purple.svg)](https://langchain-ai.github.io/langgraph/)
[![Pinecone](https://img.shields.io/badge/Pinecone-Vector_DB-orange.svg)](https://pinecone.io)
[![Gemini](https://img.shields.io/badge/Google_Gemini-2.5_Flash-red.svg)](https://ai.google.dev)

## ğŸ¯ Overview

An intelligent medical chatbot built using **RAG (Retrieval-Augmented Generation)** architecture that provides evidence-based medical answers from the **MedMCQA dataset**. The system combines semantic search with advanced AI to deliver accurate, contextual medical information.

### âœ¨ Key Features

- ğŸ§  **182,822+ Medical Q&As** from MedMCQA dataset
- ğŸ” **Semantic Vector Search** with confidence scoring
- ğŸ¤– **AI-Powered Responses** using Google Gemini 2.5 Flash
- ğŸŒ **Beautiful Web Interface** with real-time chat
- ğŸ“¡ **RESTful API** for integration
- ğŸ”„ **LangGraph Flow** for conversation management
- ğŸ“Š **Confidence Indicators** for response reliability

## ğŸ—ï¸ Architecture

```mermaid
graph TD
    A[User Question] --> B[Medical Embedder]
    B --> C[Pinecone Vector Search]
    C --> D[Context Retrieval]
    D --> E[Confidence Check]
    E --> F{Confidence >= Threshold?}
    F -->|Yes| G[Google Gemini LLM]
    F -->|No| H[Fallback Response]
    G --> I[Structured JSON Response]
    H --> I
    I --> J[Web Interface / API]
```

### ğŸ§© Components

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Embeddings** | all-MiniLM-L6-v2 | Convert text to 384-dim vectors |
| **Vector DB** | Pinecone | Semantic similarity search |
| **LLM** | Google Gemini 2.5 Flash | Generate medical responses |
| **Flow** | LangGraph | Conversation state management |
| **API** | FastAPI | Web interface & REST endpoints |
| **Frontend** | HTML/CSS/JS | Interactive chat interface |

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites

- **Python 3.8+**
- **Google API Key** ([Get here](https://ai.google.dev))
- **Pinecone API Key** ([Get here](https://pinecone.io))
- **MedMCQA Embeddings** (see setup below)

### âš¡ Installation

1. **Clone Repository**
   ```bash
   git clone https://github.com/smit-faldu/Medical-Chatbot.git
   cd Medical-Chatbot
   ```

2. **Create Virtual Environment**
   ```bash
   python -m venv venv
   # Activate: venv\Scripts\activate (Windows) or source venv/bin/activate (macOS/Linux)
   ```

3. **Install Requirements**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set Environment Variables**
   Create `.env` file:
   ```env
   GOOGLE_API_KEY=your_google_api_key_here
   PINECONE_API_KEY=your_pinecone_api_key_here
   PINECONE_INDEX_NAME=medmcqa-embeddings
   PINECONE_ENVIRONMENT=us-east-1-aws
   ```

5. **Run Notebook for Embeddings**
   ```bash
   jupyter notebook pineconeembd.ipynb
   ```
   Or use Google Colab: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1-0CZm0M_my8GOYDoYFB6xDMQi2wUBHx3#scrollTo=greE9fAEykFa)

6. **Run Server**
   ```bash
   python main.py
   ```

## ğŸŒ Access Your Chatbot

Once running, access your chatbot at:

- **ğŸ’¬ Chat Interface**: http://127.0.0.1:7860/ui
- **ğŸ“š API Documentation**: http://127.0.0.1:7860/docs
- **â¤ï¸ Health Check**: http://127.0.0.1:7860/health

## ğŸ§ª Sample Questions

Try these medical questions:

- "What is hypertension and what causes it?"
- "What are the symptoms of diabetes mellitus?"
- "How does aspirin work as an antiplatelet agent?"
- "What is the difference between Type 1 and Type 2 diabetes?"
- "What are the side effects of ACE inhibitors?"

## ğŸ¨ Design Choices & Justification

### ğŸ”„ LangGraph Structure

**Why LangGraph?**
- âœ… **State Management**: Maintains conversation context and flow
- âœ… **Conditional Logic**: Handles confidence-based routing
- âœ… **Error Handling**: Graceful fallbacks for failed operations
- âœ… **Modularity**: Clean separation of concerns (retrieval â†’ confidence â†’ generation)
- âœ… **Debugging**: Clear state transitions for troubleshooting

**Flow Design:**
```python
User Input â†’ Retrieval â†’ Confidence Check â†’ LLM/Fallback â†’ Response
```

### ğŸ¤– LLM Choice: Google Gemini 2.5 Flash

**Why Gemini 2.5 Flash?**
- âœ… **Medical Knowledge**: Strong performance on medical queries
- âœ… **JSON Output**: Reliable structured response generation
- âœ… **Speed**: Fast inference for real-time chat
- âœ… **Context Window**: Large context for medical explanations
- âœ… **Cost Effective**: Good performance-to-cost ratio

### ğŸ” Embedding Strategy: all-MiniLM-L6-v2

**Why this model?**
- âœ… **Proven Performance**: Excellent for medical Q&A similarity
- âœ… **Efficiency**: 384 dimensions - fast search, good accuracy
- âœ… **Compatibility**: Works well with MedMCQA dataset
- âœ… **Resource Friendly**: Runs efficiently on CPU

### ğŸ—„ï¸ Vector Database: Pinecone

**Why Pinecone?**
- âœ… **Scalability**: Handles 182K+ vectors efficiently
- âœ… **Speed**: Sub-second similarity search
- âœ… **Reliability**: Managed service with high uptime
- âœ… **Metadata**: Rich filtering and metadata support
- âœ… **Integration**: Excellent Python SDK

### ğŸ¯ RAG Implementation Techniques

1. **Confidence-Based Routing**
   ```python
   if confidence >= threshold:
       return llm_response
   else:
       return fallback_response
   ```

2. **Context Formatting**
   - Structured medical context from MedMCQA
   - Question + Options + Explanation + Subject
   - Optimized for LLM understanding

3. **Response Validation**
   - JSON schema validation
   - Fallback parsing for malformed responses
   - Error handling with graceful degradation

4. **Semantic Search Optimization**
   - Normalized embeddings for cosine similarity
   - Configurable similarity thresholds
   - Multi-document context aggregation

## ğŸ“ Project Structure

```
nexgAI-medical-chatbot/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ embedder.py              # Medical text embedder
â”‚   â”œâ”€â”€ pinecone_retriever.py    # Vector search & retrieval
â”‚   â”œâ”€â”€ llm.py                   # Google Gemini integration
â”‚   â”œâ”€â”€ flow.py                  # LangGraph conversation flow
â”‚   â””â”€â”€ api.py                   # FastAPI web application
â”œâ”€â”€ static/                       # Web interface
â”‚   â””â”€â”€ index.html               # Chat UI
â”œâ”€â”€ data/                        # Data directory (optional)
â”œâ”€â”€ pineconeembd.ipynb          # Embedding creation notebook
â”œâ”€â”€ main.py                     # Application entry point
â”œâ”€â”€ start.py                    # Quick start script
â”œâ”€â”€ test_system.py              # System testing
â”œâ”€â”€ check_pinecone.py           # Pinecone verification
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # Environment variables
â””â”€â”€ README.md                   # This file
```

## ğŸ§ª Sample Questions

Try these medical questions:

1. **"What is hypertension and what causes it?"**
2. **"What are the symptoms of diabetes mellitus?"**
3. **"How does aspirin work as an antiplatelet agent?"**
4. **"What is the difference between Type 1 and Type 2 diabetes?"**
5. **"What are the side effects of ACE inhibitors?"**
6. **"What causes myocardial infarction?"**
7. **"How is pneumonia diagnosed?"**
8. **"What is the mechanism of action of beta-blockers?"**

## ğŸ“Š Performance Metrics

| Metric | Value |
|--------|-------|
| **Database Size** | 182,822 medical Q&As |
| **Response Time** | ~2-5 seconds |
| **Search Accuracy** | High confidence (>0.7) for medical queries |
| **Embedding Dimension** | 384 (optimized for speed) |
| **Concurrent Users** | Supports multiple simultaneous chats |

## ğŸ› ï¸ API Usage

### Chat Endpoint

```bash
curl -X POST "http://127.0.0.1:8000/chat" \
     -H "Content-Type: application/json" \
     -d '{"question": "What is hypertension?"}'
```

**Response:**
```json
{
  "question": "What is hypertension?",
  "answer": "Hypertension is persistently elevated blood pressure...",
  "explanation": "Detailed medical explanation...",
  "key_points": ["High blood pressure", "Cardiovascular risk", "Treatment options"],
  "subject": "Cardiology",
  "confidence": 0.85,
  "source": "MedMCQA",
  "is_fallback": false
}
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `GOOGLE_API_KEY` | Google Gemini API key | Required |
| `PINECONE_API_KEY` | Pinecone API key | Required |
| `PINECONE_INDEX_NAME` | Pinecone index name | `medmcqa-embeddings` |
| `PINECONE_ENVIRONMENT` | Pinecone environment | `us-east-1-aws` |
| `PINECONE_MODEL` | Embedding model name | `all-MiniLM-L6-v2` |

### Confidence Threshold

Adjust the confidence threshold in `src/flow.py`:
```python
# Higher = more strict, Lower = more permissive
confidence_threshold = 0.3  # Default: 0.3
```

## ğŸ› Troubleshooting

### Common Issues

1. **"Index not found" error**
   ```bash
   # Check your Pinecone indexes
   python check_pinecone.py
   ```

2. **"Model not found" error**
   ```bash
   # Verify embedding model
   python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')"
   ```

3. **"API key invalid" error**
   - Check your `.env` file
   - Verify API keys are correct
   - Ensure no extra spaces in keys

4. **Low confidence responses**
   - Lower the confidence threshold
   - Check if your question is medical-related
   - Verify Pinecone index has data

### Debug Mode

Run with debug logging:
```bash
python main.py --debug
```

## ğŸš€ Deployment

### Docker Deployment (Recommended)

We provide optimized multi-stage Docker builds for production deployment:

#### Quick Start with Docker
```bash
# Linux/macOS
chmod +x deploy.sh
./deploy.sh deploy prod

# Windows PowerShell
.\deploy.ps1 deploy prod
```

#### Manual Docker Compose
```bash
# Development
docker-compose up -d --build

# Production (with Nginx reverse proxy)
docker-compose -f docker-compose.prod.yml up -d --build
```

**Features:**
- âœ… **Multi-stage build**: Optimized image size (~500MB)
- âœ… **Security**: Non-root user, minimal attack surface
- âœ… **Performance**: Pre-cached models and dependencies
- âœ… **Monitoring**: Health checks and logging
- âœ… **Scaling**: Nginx load balancer ready

ğŸ“– **See [DEPLOYMENT.md](DEPLOYMENT.md) for complete Docker deployment guide**

### Local Production
```bash
# Install production server
pip install gunicorn

# Run with Gunicorn
gunicorn src.api:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests: `python test_system.py`
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- **MedMCQA Dataset**: Medical question-answer pairs
- **Sentence Transformers**: Embedding models
- **Pinecone**: Vector database platform
- **Google**: Gemini AI model
- **LangChain**: LangGraph framework

## ğŸ“ Support

- ğŸ§ª **Run Tests**: `python test_system.py`
- ğŸ“Š **Check Health**: http://127.0.0.1:8000/health
- ğŸ“š **API Docs**: http://127.0.0.1:8000/docs
- ğŸ” **Debug**: Check console logs for errors

---

**ğŸ¥ Medical Chatbot - Providing Evidence-Based Medical Information**  
**Built with â¤ï¸ for the NexgAI AI Engineering Challenge**