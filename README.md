# üè• Medical Chatbot - NexgAI AI Engineering Challenge

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![LangGraph](https://img.shields.io/badge/LangGraph-Latest-purple.svg)](https://langchain-ai.github.io/langgraph/)
[![Pinecone](https://img.shields.io/badge/Pinecone-Vector_DB-orange.svg)](https://pinecone.io)
[![Gemini](https://img.shields.io/badge/Google_Gemini-2.5_Flash-red.svg)](https://ai.google.dev)

## üéØ Overview

An intelligent medical chatbot built using **RAG (Retrieval-Augmented Generation)** architecture that provides evidence-based medical answers from the **MedMCQA dataset**. The system combines semantic search with advanced AI to deliver accurate, contextual medical information.

### ‚ú® Key Features

- üß† **182,822+ Medical Q&As** from MedMCQA dataset
- üîç **Semantic Vector Search** with confidence scoring
- ü§ñ **AI-Powered Responses** using Google Gemini 2.5 Flash
- üåê **Beautiful Web Interface** with real-time chat
- üì° **RESTful API** for integration
- üîÑ **LangGraph Flow** for conversation management
- üìä **Confidence Indicators** for response reliability

## üèóÔ∏è Architecture

```mermaid
graph TD
    A[User Question] --> B[Medical Embedder]
    B --> C[Pinecone Vector Search]
    C --> D[Context Retrieval]
    D --> E[Confidence Check]
    E --> F{Confidence >= Threshold?}
    F -->|Yes| G[Google Gemini LLM]
    F -->|No| H[Fallback Response]
    G --> I[Structured JSON Response]
    H --> I
    I --> J[Web Interface / API]
```

### üß© Components

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Embeddings** | all-MiniLM-L6-v2 | Convert text to 384-dim vectors |
| **Vector DB** | Pinecone | Semantic similarity search |
| **LLM** | Google Gemini 2.5 Flash | Generate medical responses |
| **Flow** | LangGraph | Conversation state management |
| **API** | FastAPI | Web interface & REST endpoints |
| **Frontend** | HTML/CSS/JS | Interactive chat interface |

## üöÄ Quick Start

### üìã Prerequisites

- **Python 3.8+**
- **Google API Key** ([Get here](https://ai.google.dev))
- **Pinecone API Key** ([Get here](https://pinecone.io))
- **MedMCQA Embeddings** (see setup below)

### ‚ö° Installation

1. **Clone Repository**
   ```bash
   git clone https://github.com/smit-faldu/Medical-Chatbot.git
   cd Medical-Chatbot
   ```

2. **Create Virtual Environment**
   ```bash
   python -m venv venv
   # Activate: venv\Scripts\activate (Windows) or source venv/bin/activate (macOS/Linux)
   ```

3. **Install Requirements**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set Environment Variables**
   Create `.env` file:
   ```env
   GOOGLE_API_KEY=your_google_api_key_here
   PINECONE_API_KEY=your_pinecone_api_key_here
   PINECONE_INDEX_NAME=medmcqa-embeddings
   PINECONE_ENVIRONMENT=us-east-1-aws
   ```

5. **Run Notebook for Embeddings**
   ```bash
   jupyter notebook pineconeembd.ipynb
   ```
   Or use Google Colab: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1-0CZm0M_my8GOYDoYFB6xDMQi2wUBHx3#scrollTo=greE9fAEykFa)

6. **Run Server**
   ```bash
   python main.py
   ```

## üåê Access Your Chatbot

Once running, access your chatbot at:

- **üí¨ Chat Interface**: http://127.0.0.1:7860/ui
- **üìö API Documentation**: http://127.0.0.1:7860/docs
- **‚ù§Ô∏è Health Check**: http://127.0.0.1:7860/health

## üß™ Sample Questions

Try these medical questions:

- "What is hypertension and what causes it?"
- "What are the symptoms of diabetes mellitus?"
- "How does aspirin work as an antiplatelet agent?"
- "What is the difference between Type 1 and Type 2 diabetes?"
- "What are the side effects of ACE inhibitors?"

## üé® Design Choices & Justification

### üîÑ LangGraph Structure

**Why LangGraph?**
- ‚úÖ **State Management**: Maintains conversation context and flow
- ‚úÖ **Conditional Logic**: Handles confidence-based routing
- ‚úÖ **Error Handling**: Graceful fallbacks for failed operations
- ‚úÖ **Modularity**: Clean separation of concerns (retrieval ‚Üí confidence ‚Üí generation)
- ‚úÖ **Debugging**: Clear state transitions for troubleshooting

**Flow Design:**
```python
User Input ‚Üí Retrieval ‚Üí Confidence Check ‚Üí LLM/Fallback ‚Üí Response
```

### ü§ñ LLM Choice: Google Gemini 2.5 Flash

**Why Gemini 2.5 Flash?**
- ‚úÖ **Medical Knowledge**: Strong performance on medical queries
- ‚úÖ **JSON Output**: Reliable structured response generation
- ‚úÖ **Speed**: Fast inference for real-time chat
- ‚úÖ **Context Window**: Large context for medical explanations
- ‚úÖ **Cost Effective**: Good performance-to-cost ratio

### üîç Embedding Strategy: all-MiniLM-L6-v2

**Why this model?**
- ‚úÖ **Proven Performance**: Excellent for medical Q&A similarity
- ‚úÖ **Efficiency**: 384 dimensions - fast search, good accuracy
- ‚úÖ **Compatibility**: Works well with MedMCQA dataset
- ‚úÖ **Resource Friendly**: Runs efficiently on CPU

### üóÑÔ∏è Vector Database: Pinecone

**Why Pinecone?**
- ‚úÖ **Scalability**: Handles 182K+ vectors efficiently
- ‚úÖ **Speed**: Sub-second similarity search
- ‚úÖ **Reliability**: Managed service with high uptime
- ‚úÖ **Metadata**: Rich filtering and metadata support
- ‚úÖ **Integration**: Excellent Python SDK

### üéØ RAG Implementation Techniques

1. **Confidence-Based Routing**
   ```python
   if confidence >= threshold:
       return llm_response
   else:
       return fallback_response
   ```

2. **Context Formatting**
   - Structured medical context from MedMCQA
   - Question + Options + Explanation + Subject
   - Optimized for LLM understanding

3. **Response Validation**
   - JSON schema validation
   - Fallback parsing for malformed responses
   - Error handling with graceful degradation

4. **Semantic Search Optimization**
   - Normalized embeddings for cosine similarity
   - Configurable similarity thresholds
   - Multi-document context aggregation

## üìÅ Project Structure

```
nexgAI-medical-chatbot/
‚îú‚îÄ‚îÄ src/                          # Source code
‚îÇ   ‚îú‚îÄ‚îÄ embedder.py              # Medical text embedder
‚îÇ   ‚îú‚îÄ‚îÄ pinecone_retriever.py    # Vector search & retrieval
‚îÇ   ‚îú‚îÄ‚îÄ llm.py                   # Google Gemini integration
‚îÇ   ‚îú‚îÄ‚îÄ flow.py                  # LangGraph conversation flow
‚îÇ   ‚îî‚îÄ‚îÄ api.py                   # FastAPI web application
‚îú‚îÄ‚îÄ static/                       # Web interface
‚îÇ   ‚îî‚îÄ‚îÄ index.html               # Chat UI
‚îú‚îÄ‚îÄ data/                        # Data directory (optional)
‚îú‚îÄ‚îÄ pineconeembd.ipynb          # Embedding creation notebook
‚îú‚îÄ‚îÄ main.py                     # Application entry point
‚îú‚îÄ‚îÄ start.py                    # Quick start script
‚îú‚îÄ‚îÄ test_system.py              # System testing
‚îú‚îÄ‚îÄ check_pinecone.py           # Pinecone verification
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ .env                        # Environment variables
‚îî‚îÄ‚îÄ README.md                   # This file
```

## üß™ Sample Questions

Try these medical questions:

1. **"What is hypertension and what causes it?"**
2. **"What are the symptoms of diabetes mellitus?"**
3. **"How does aspirin work as an antiplatelet agent?"**
4. **"What is the difference between Type 1 and Type 2 diabetes?"**
5. **"What are the side effects of ACE inhibitors?"**
6. **"What causes myocardial infarction?"**
7. **"How is pneumonia diagnosed?"**
8. **"What is the mechanism of action of beta-blockers?"**

## üìä Performance Metrics

| Metric | Value |
|--------|-------|
| **Database Size** | 182,822 medical Q&As |
| **Response Time** | ~2-5 seconds |
| **Search Accuracy** | High confidence (>0.7) for medical queries |
| **Embedding Dimension** | 384 (optimized for speed) |
| **Concurrent Users** | Supports multiple simultaneous chats |

## üõ†Ô∏è API Usage

### Chat Endpoint

```bash
curl -X POST "http://127.0.0.1:8000/chat" \
     -H "Content-Type: application/json" \
     -d '{"question": "What is hypertension?"}'
```

**Response:**
```json
{
  "question": "What is hypertension?",
  "answer": "Hypertension is persistently elevated blood pressure...",
  "explanation": "Detailed medical explanation...",
  "key_points": ["High blood pressure", "Cardiovascular risk", "Treatment options"],
  "subject": "Cardiology",
  "confidence": 0.85,
  "source": "MedMCQA",
  "is_fallback": false
}
```

## üîß Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `GOOGLE_API_KEY` | Google Gemini API key | Required |
| `PINECONE_API_KEY` | Pinecone API key | Required |
| `PINECONE_INDEX_NAME` | Pinecone index name | `medmcqa-embeddings` |
| `PINECONE_ENVIRONMENT` | Pinecone environment | `us-east-1-aws` |
| `PINECONE_MODEL` | Embedding model name | `all-MiniLM-L6-v2` |

### Confidence Threshold

Adjust the confidence threshold in `src/flow.py`:
```python
# Higher = more strict, Lower = more permissive
confidence_threshold = 0.3  # Default: 0.3
```

## üêõ Troubleshooting

### Common Issues

1. **"Index not found" error**
   ```bash
   # Check your Pinecone indexes
   python check_pinecone.py
   ```

2. **"Model not found" error**
   ```bash
   # Verify embedding model
   python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')"
   ```

3. **"API key invalid" error**
   - Check your `.env` file
   - Verify API keys are correct
   - Ensure no extra spaces in keys

4. **Low confidence responses**
   - Lower the confidence threshold
   - Check if your question is medical-related
   - Verify Pinecone index has data

### Debug Mode

Run with debug logging:
```bash
python main.py --debug
```

## üöÄ Deployment

### Docker Deployment (Recommended)

We provide optimized multi-stage Docker builds for production deployment:

#### Quick Start with Docker
```bash
# Linux/macOS
chmod +x deploy.sh
./deploy.sh deploy prod

# Windows PowerShell
.\deploy.ps1 deploy prod
```

#### Manual Docker Compose
```bash
# Development
docker-compose up -d --build

# Production (with Nginx reverse proxy)
docker-compose -f docker-compose.prod.yml up -d --build
```

**Features:**
- ‚úÖ **Multi-stage build**: Optimized image size (~500MB)
- ‚úÖ **Security**: Non-root user, minimal attack surface
- ‚úÖ **Performance**: Pre-cached models and dependencies
- ‚úÖ **Monitoring**: Health checks and logging
- ‚úÖ **Scaling**: Nginx load balancer ready

üìñ **See [DEPLOYMENT.md](DEPLOYMENT.md) for complete Docker deployment guide**

### Local Production
```bash
# Install production server
pip install gunicorn

# Run with Gunicorn
gunicorn src.api:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests: `python test_system.py`
5. Submit a pull request

## üìÑ License

This project is licensed under the MIT License.

## üôè Acknowledgments

- **MedMCQA Dataset**: Medical question-answer pairs
- **Sentence Transformers**: Embedding models
- **Pinecone**: Vector database platform
- **Google**: Gemini AI model
- **LangChain**: LangGraph framework

## üìû Support

- üß™ **Run Tests**: `python test_system.py`
- üìä **Check Health**: http://127.0.0.1:8000/health
- üìö **API Docs**: http://127.0.0.1:8000/docs
- üîç **Debug**: Check console logs for errors

---

**üè• Medical Chatbot - Providing Evidence-Based Medical Information**  
**Built with ‚ù§Ô∏è for the NexgAI AI Engineering Challenge**